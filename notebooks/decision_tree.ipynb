{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "function build_tree(data, labels, depth=0):\n",
    "    if stop_condition(data, labels, depth):\n",
    "        return LeafNode(class = majority_class(labels))\n",
    "    \n",
    "    best_gain = 0\n",
    "    best_feat, best_thresh = None, None\n",
    "    parent_impurity = impurity(labels)\n",
    "\n",
    "    for each feature j in 1…D:\n",
    "        for each threshold t in unique_values(data[:,j]):\n",
    "            left_labels  = labels[data[:,j] ≤ t]\n",
    "            right_labels = labels[data[:,j] >  t]\n",
    "\n",
    "            if len(left_labels)==0 or len(right_labels)==0: continue\n",
    "\n",
    "            gain = parent_impurity \\\n",
    "                   - (|left|/|total|)*impurity(left_labels) \\\n",
    "                   - (|right|/|total|)*impurity(right_labels)\n",
    "\n",
    "            if gain > best_gain:\n",
    "                best_gain, best_feat, best_thresh = gain, j, t\n",
    "\n",
    "    if best_gain < min_impurity_decrease:\n",
    "        return LeafNode(class = majority_class(labels))\n",
    "\n",
    "    left_data, left_labels  = split(data, labels, best_feat, best_thresh, side=\"left\")\n",
    "    right_data, right_labels = split(data, labels, best_feat, best_thresh, side=\"right\")\n",
    "\n",
    "    left_subtree  = build_tree(left_data,  left_labels,  depth+1)\n",
    "    right_subtree = build_tree(right_data, right_labels, depth+1)\n",
    "\n",
    "    return DecisionNode(\n",
    "        feature_index = best_feat,\n",
    "        threshold     = best_thresh,\n",
    "        left          = left_subtree,\n",
    "        right         = right_subtree\n",
    "    )\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "data = datasets.load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1234\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1       2       3        4        5       6        7       8   \\\n",
       "0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419   \n",
       "1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n",
       "2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n",
       "3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520  0.2597   \n",
       "4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430  0.1809   \n",
       "\n",
       "        9       10      11     12      13        14       15       16  \\\n",
       "0  0.07871  1.0950  0.9053  8.589  153.40  0.006399  0.04904  0.05373   \n",
       "1  0.05667  0.5435  0.7339  3.398   74.08  0.005225  0.01308  0.01860   \n",
       "2  0.05999  0.7456  0.7869  4.585   94.03  0.006150  0.04006  0.03832   \n",
       "3  0.09744  0.4956  1.1560  3.445   27.23  0.009110  0.07458  0.05661   \n",
       "4  0.05883  0.7572  0.7813  5.438   94.44  0.011490  0.02461  0.05688   \n",
       "\n",
       "        17       18        19     20     21      22      23      24      25  \\\n",
       "0  0.01587  0.03003  0.006193  25.38  17.33  184.60  2019.0  0.1622  0.6656   \n",
       "1  0.01340  0.01389  0.003532  24.99  23.41  158.80  1956.0  0.1238  0.1866   \n",
       "2  0.02058  0.02250  0.004571  23.57  25.53  152.50  1709.0  0.1444  0.4245   \n",
       "3  0.01867  0.05963  0.009208  14.91  26.50   98.87   567.7  0.2098  0.8663   \n",
       "4  0.01885  0.01756  0.005115  22.54  16.67  152.20  1575.0  0.1374  0.2050   \n",
       "\n",
       "       26      27      28       29  \n",
       "0  0.7119  0.2654  0.4601  0.11890  \n",
       "1  0.2416  0.1860  0.2750  0.08902  \n",
       "2  0.4504  0.2430  0.3613  0.08758  \n",
       "3  0.6869  0.2575  0.6638  0.17300  \n",
       "4  0.4000  0.1625  0.2364  0.07678  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0\n",
       " 1    357\n",
       " 0    212\n",
       " Name: count, dtype: int64,\n",
       " np.int64(1),\n",
       " array([212, 357]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y).value_counts(), Counter(y).most_common(1)[0][0], np.bincount(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.981,  7.691,  7.729,  7.76 ,  8.196,  8.219,  8.571,  8.597,\n",
       "        8.598,  8.618,  8.671,  8.726,  8.734,  8.878,  8.888,  8.95 ,\n",
       "        9.   ,  9.029,  9.042,  9.173,  9.268,  9.295,  9.333,  9.397,\n",
       "        9.405,  9.423,  9.436,  9.465,  9.504,  9.567,  9.606,  9.667,\n",
       "        9.668,  9.676,  9.683,  9.72 ,  9.731,  9.738,  9.742,  9.755,\n",
       "        9.777,  9.787,  9.847,  9.876,  9.904, 10.03 , 10.05 , 10.08 ,\n",
       "       10.16 , 10.17 , 10.18 , 10.2  , 10.25 , 10.26 , 10.29 , 10.32 ,\n",
       "       10.44 , 10.48 , 10.49 , 10.51 , 10.57 , 10.6  , 10.65 , 10.66 ,\n",
       "       10.71 , 10.75 , 10.8  , 10.82 , 10.86 , 10.88 , 10.9  , 10.91 ,\n",
       "       10.94 , 10.95 , 10.96 , 10.97 , 11.04 , 11.06 , 11.08 , 11.13 ,\n",
       "       11.14 , 11.15 , 11.16 , 11.2  , 11.22 , 11.25 , 11.26 , 11.27 ,\n",
       "       11.28 , 11.29 , 11.3  , 11.31 , 11.32 , 11.33 , 11.34 , 11.36 ,\n",
       "       11.37 , 11.41 , 11.42 , 11.43 , 11.45 , 11.46 , 11.47 , 11.49 ,\n",
       "       11.5  , 11.51 , 11.52 , 11.54 , 11.57 , 11.6  , 11.61 , 11.62 ,\n",
       "       11.63 , 11.64 , 11.66 , 11.67 , 11.68 , 11.69 , 11.7  , 11.71 ,\n",
       "       11.74 , 11.75 , 11.76 , 11.8  , 11.81 , 11.84 , 11.85 , 11.87 ,\n",
       "       11.89 , 11.9  , 11.93 , 11.94 , 11.95 , 11.99 , 12.   , 12.03 ,\n",
       "       12.04 , 12.05 , 12.06 , 12.07 , 12.1  , 12.16 , 12.18 , 12.19 ,\n",
       "       12.2  , 12.21 , 12.22 , 12.23 , 12.25 , 12.27 , 12.3  , 12.31 ,\n",
       "       12.32 , 12.34 , 12.36 , 12.39 , 12.4  , 12.42 , 12.43 , 12.45 ,\n",
       "       12.46 , 12.47 , 12.49 , 12.54 , 12.56 , 12.58 , 12.62 , 12.63 ,\n",
       "       12.65 , 12.67 , 12.68 , 12.7  , 12.72 , 12.75 , 12.76 , 12.77 ,\n",
       "       12.78 , 12.8  , 12.81 , 12.83 , 12.85 , 12.86 , 12.87 , 12.88 ,\n",
       "       12.89 , 12.9  , 12.91 , 12.94 , 12.95 , 12.96 , 12.98 , 12.99 ,\n",
       "       13.   , 13.01 , 13.03 , 13.05 , 13.08 , 13.11 , 13.14 , 13.15 ,\n",
       "       13.16 , 13.17 , 13.2  , 13.21 , 13.24 , 13.27 , 13.28 , 13.3  ,\n",
       "       13.34 , 13.37 , 13.38 , 13.4  , 13.43 , 13.44 , 13.45 , 13.46 ,\n",
       "       13.47 , 13.48 , 13.49 , 13.5  , 13.51 , 13.53 , 13.54 , 13.56 ,\n",
       "       13.59 , 13.61 , 13.62 , 13.64 , 13.65 , 13.66 , 13.68 , 13.69 ,\n",
       "       13.7  , 13.71 , 13.73 , 13.74 , 13.75 , 13.77 , 13.78 , 13.8  ,\n",
       "       13.81 , 13.82 , 13.85 , 13.86 , 13.87 , 13.88 , 13.9  , 13.94 ,\n",
       "       13.96 , 13.98 , 14.02 , 14.03 , 14.04 , 14.05 , 14.06 , 14.11 ,\n",
       "       14.19 , 14.2  , 14.22 , 14.25 , 14.26 , 14.27 , 14.29 , 14.34 ,\n",
       "       14.4  , 14.41 , 14.42 , 14.44 , 14.45 , 14.47 , 14.48 , 14.5  ,\n",
       "       14.53 , 14.54 , 14.58 , 14.59 , 14.6  , 14.61 , 14.62 , 14.64 ,\n",
       "       14.68 , 14.69 , 14.71 , 14.74 , 14.76 , 14.78 , 14.8  , 14.81 ,\n",
       "       14.86 , 14.87 , 14.9  , 14.92 , 14.95 , 14.96 , 14.97 , 14.99 ,\n",
       "       15.   , 15.04 , 15.05 , 15.06 , 15.08 , 15.1  , 15.12 , 15.13 ,\n",
       "       15.19 , 15.22 , 15.27 , 15.28 , 15.3  , 15.32 , 15.34 , 15.37 ,\n",
       "       15.46 , 15.49 , 15.5  , 15.53 , 15.61 , 15.66 , 15.7  , 15.71 ,\n",
       "       15.73 , 15.75 , 15.78 , 15.85 , 16.02 , 16.03 , 16.07 , 16.11 ,\n",
       "       16.13 , 16.14 , 16.16 , 16.17 , 16.24 , 16.25 , 16.26 , 16.27 ,\n",
       "       16.3  , 16.35 , 16.46 , 16.5  , 16.6  , 16.65 , 16.69 , 16.74 ,\n",
       "       16.78 , 16.84 , 17.01 , 17.02 , 17.05 , 17.06 , 17.08 , 17.14 ,\n",
       "       17.19 , 17.2  , 17.27 , 17.29 , 17.3  , 17.35 , 17.42 , 17.46 ,\n",
       "       17.47 , 17.54 , 17.57 , 17.6  , 17.68 , 17.75 , 17.85 , 17.91 ,\n",
       "       17.93 , 17.95 , 17.99 , 18.01 , 18.03 , 18.05 , 18.08 , 18.22 ,\n",
       "       18.25 , 18.31 , 18.45 , 18.46 , 18.49 , 18.61 , 18.63 , 18.65 ,\n",
       "       18.66 , 18.77 , 18.81 , 18.82 , 18.94 , 19.   , 19.02 , 19.07 ,\n",
       "       19.1  , 19.16 , 19.17 , 19.18 , 19.19 , 19.21 , 19.27 , 19.4  ,\n",
       "       19.44 , 19.45 , 19.53 , 19.55 , 19.59 , 19.68 , 19.69 , 19.73 ,\n",
       "       19.79 , 19.8  , 19.81 , 19.89 , 20.09 , 20.13 , 20.16 , 20.18 ,\n",
       "       20.2  , 20.26 , 20.29 , 20.31 , 20.34 , 20.44 , 20.47 , 20.48 ,\n",
       "       20.51 , 20.55 , 20.57 , 20.58 , 20.59 , 20.6  , 20.64 , 20.73 ,\n",
       "       20.92 , 20.94 , 21.09 , 21.1  , 21.16 , 21.37 , 21.56 , 21.61 ,\n",
       "       21.71 , 21.75 , 22.01 , 22.27 , 23.09 , 23.21 , 23.27 , 23.29 ,\n",
       "       23.51 , 24.25 , 24.63 , 25.22 , 25.73 , 27.22 , 27.42 , 28.11 ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_vals = np.unique(X[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "455"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_vals[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class DecisionNode:\n",
    "    def __init__(self, feature_index, threshold, left, right):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "class LeafNode:\n",
    "    def __init__(self, prediction):\n",
    "        self.prediction = prediction\n",
    "\n",
    "class CustomDecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2,\n",
    "                 min_impurity_decrease=1e-7, criterion=\"gini\"):\n",
    "        assert criterion in (\"gini\", \"entropy\", \"misclassification\"), \\\n",
    "            \"criterion must be 'gini', 'entropy', or 'misclassification'\"\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.criterion = criterion\n",
    "        self.n_classes = None\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        self.n_classes = len(set(y))\n",
    "        self.root = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_one(x, self.root) for x in X])\n",
    "\n",
    "    def print_tree(self):\n",
    "        self._print_node(self.root, spacing=\"\")\n",
    "\n",
    "    def _print_node(self, node, spacing):\n",
    "        if isinstance(node, LeafNode):\n",
    "            print(spacing + f\"Predict → {node.prediction}\")\n",
    "            return\n",
    "        print(spacing + f\"[X[{node.feature_index}] ≤ {node.threshold:.4f}]\")\n",
    "        print(spacing + \" ➜ True:\")\n",
    "        self._print_node(node.left, spacing + \"    \")\n",
    "        print(spacing + \" ➜ False:\")\n",
    "        self._print_node(node.right, spacing + \"    \")\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        num_samples, num_features = X.shape\n",
    "        # stopping criteria\n",
    "        if (depth == self.max_depth or\n",
    "            num_samples < self.min_samples_split or\n",
    "            len(set(y)) == 1):\n",
    "            leaf_label = Counter(y).most_common(1)[0][0]\n",
    "            return LeafNode(leaf_label)\n",
    "\n",
    "        parent_impurity = self._impurity(y)\n",
    "        best_gain = 0.0\n",
    "        best_feat = None\n",
    "        best_thresh = None\n",
    "\n",
    "        # find best split\n",
    "        for feat in range(num_features):\n",
    "            unique_vals = np.unique(X[:, feat])\n",
    "            if unique_vals.shape[0] > 1:\n",
    "                thresholds = (unique_vals[:-1] + unique_vals[1:]) / 2\n",
    "            else:\n",
    "                continue\n",
    "            for thresh in thresholds:\n",
    "                left_mask = X[:, feat] <= thresh\n",
    "                right_mask = ~left_mask\n",
    "                if left_mask.sum() == 0 or right_mask.sum() == 0:\n",
    "                    continue\n",
    "                gain = self._information_gain(y, left_mask, right_mask, parent_impurity)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feat = feat\n",
    "                    best_thresh = thresh\n",
    "\n",
    "        # no valid split found\n",
    "        if best_gain < self.min_impurity_decrease:\n",
    "            leaf_label = Counter(y).most_common(1)[0][0]\n",
    "            return LeafNode(leaf_label)\n",
    "\n",
    "        # split on best feature/threshold\n",
    "        mask_left = X[:, best_feat] <= best_thresh\n",
    "        mask_right = ~mask_left\n",
    "        left_subtree = self._build_tree(X[mask_left], y[mask_left], depth+1)\n",
    "        right_subtree = self._build_tree(X[mask_right], y[mask_right], depth+1)\n",
    "        return DecisionNode(best_feat, best_thresh, left_subtree, right_subtree)\n",
    "\n",
    "    def _impurity(self, y):\n",
    "        counts = np.bincount(y, minlength=self.n_classes)\n",
    "        ps = counts / counts.sum()\n",
    "        if self.criterion == \"gini\":\n",
    "            return 1 - np.sum(ps**2)\n",
    "        elif self.criterion == \"entropy\":\n",
    "            return -np.sum([p * np.log2(p) for p in ps if p > 0])\n",
    "        else:  # misclassification error\n",
    "            return 1 - np.max(ps)\n",
    "\n",
    "    def _information_gain(self, y, left_mask, right_mask, parent_impurity):\n",
    "        n = len(y)\n",
    "        n_left = left_mask.sum()\n",
    "        n_right = right_mask.sum()\n",
    "        imp_left = self._impurity(y[left_mask])\n",
    "        imp_right = self._impurity(y[right_mask])\n",
    "        child_impurity = (n_left/n)*imp_left + (n_right/n)*imp_right\n",
    "        return parent_impurity - child_impurity\n",
    "\n",
    "    def _predict_one(self, x, node):\n",
    "        if isinstance(node, LeafNode):\n",
    "            return node.prediction\n",
    "        if x[node.feature_index] <= node.threshold:\n",
    "            return self._predict_one(x, node.left)\n",
    "        else:\n",
    "            return self._predict_one(x, node.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9122807017543859\n",
      "Sklearn Accuracy: 0.9122807017543859\n"
     ]
    }
   ],
   "source": [
    "tree = CustomDecisionTreeClassifier(max_depth=5, min_samples_split=2, criterion=\"gini\")\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy(y_test, y_pred))\n",
    "\n",
    "# Check if the implementation is correct\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "sk_tree = DecisionTreeClassifier(max_depth=5, min_samples_split=2, criterion=\"gini\")\n",
    "sk_tree.fit(X_train, y_train)\n",
    "y_sk_pred = sk_tree.predict(X_test)\n",
    "\n",
    "print(\"Sklearn Accuracy:\", accuracy(y_test, y_sk_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-mlcore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
