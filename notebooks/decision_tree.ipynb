{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "function build_tree(data, labels, depth=0):\n",
    "    if stop_condition(data, labels, depth):\n",
    "        return LeafNode(class = majority_class(labels))\n",
    "    \n",
    "    best_gain = 0\n",
    "    best_feat, best_thresh = None, None\n",
    "    parent_impurity = impurity(labels)\n",
    "\n",
    "    for each feature j in 1…D:\n",
    "        for each threshold t in unique_values(data[:,j]):\n",
    "            left_labels  = labels[data[:,j] ≤ t]\n",
    "            right_labels = labels[data[:,j] >  t]\n",
    "\n",
    "            if len(left_labels)==0 or len(right_labels)==0: continue\n",
    "\n",
    "            gain = parent_impurity \\\n",
    "                   - (|left|/|total|)*impurity(left_labels) \\\n",
    "                   - (|right|/|total|)*impurity(right_labels)\n",
    "\n",
    "            if gain > best_gain:\n",
    "                best_gain, best_feat, best_thresh = gain, j, t\n",
    "\n",
    "    if best_gain < min_impurity_decrease:\n",
    "        return LeafNode(class = majority_class(labels))\n",
    "\n",
    "    left_data, left_labels  = split(data, labels, best_feat, best_thresh, side=\"left\")\n",
    "    right_data, right_labels = split(data, labels, best_feat, best_thresh, side=\"right\")\n",
    "\n",
    "    left_subtree  = build_tree(left_data,  left_labels,  depth+1)\n",
    "    right_subtree = build_tree(right_data, right_labels, depth+1)\n",
    "\n",
    "    return DecisionNode(\n",
    "        feature_index = best_feat,\n",
    "        threshold     = best_thresh,\n",
    "        left          = left_subtree,\n",
    "        right         = right_subtree\n",
    "    )\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "data = datasets.load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1234\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1       2       3        4        5       6        7       8   \\\n",
       "0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419   \n",
       "1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n",
       "2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n",
       "3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520  0.2597   \n",
       "4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430  0.1809   \n",
       "\n",
       "        9       10      11     12      13        14       15       16  \\\n",
       "0  0.07871  1.0950  0.9053  8.589  153.40  0.006399  0.04904  0.05373   \n",
       "1  0.05667  0.5435  0.7339  3.398   74.08  0.005225  0.01308  0.01860   \n",
       "2  0.05999  0.7456  0.7869  4.585   94.03  0.006150  0.04006  0.03832   \n",
       "3  0.09744  0.4956  1.1560  3.445   27.23  0.009110  0.07458  0.05661   \n",
       "4  0.05883  0.7572  0.7813  5.438   94.44  0.011490  0.02461  0.05688   \n",
       "\n",
       "        17       18        19     20     21      22      23      24      25  \\\n",
       "0  0.01587  0.03003  0.006193  25.38  17.33  184.60  2019.0  0.1622  0.6656   \n",
       "1  0.01340  0.01389  0.003532  24.99  23.41  158.80  1956.0  0.1238  0.1866   \n",
       "2  0.02058  0.02250  0.004571  23.57  25.53  152.50  1709.0  0.1444  0.4245   \n",
       "3  0.01867  0.05963  0.009208  14.91  26.50   98.87   567.7  0.2098  0.8663   \n",
       "4  0.01885  0.01756  0.005115  22.54  16.67  152.20  1575.0  0.1374  0.2050   \n",
       "\n",
       "       26      27      28       29  \n",
       "0  0.7119  0.2654  0.4601  0.11890  \n",
       "1  0.2416  0.1860  0.2750  0.08902  \n",
       "2  0.4504  0.2430  0.3613  0.08758  \n",
       "3  0.6869  0.2575  0.6638  0.17300  \n",
       "4  0.4000  0.1625  0.2364  0.07678  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0\n",
       " 1    357\n",
       " 0    212\n",
       " Name: count, dtype: int64,\n",
       " np.int64(1),\n",
       " array([212, 357]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y).value_counts(), Counter(y).most_common(1)[0][0], np.bincount(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(395)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X[:, 0] < 15).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class DecisionNode:\n",
    "    def __init__(self, feature_index, threshold, left, right):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "class LeafNode:\n",
    "    def __init__(self, prediction):\n",
    "        self.prediction = prediction\n",
    "\n",
    "class CustomDecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2,\n",
    "                 min_impurity_decrease=1e-7, criterion=\"gini\"):\n",
    "        assert criterion in (\"gini\", \"entropy\", \"misclassification\"), \\\n",
    "            \"criterion must be 'gini', 'entropy', or 'misclassification'\"\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.criterion = criterion\n",
    "        self.n_classes = None\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        self.n_classes = len(set(y))\n",
    "        self.root = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_one(x, self.root) for x in X])\n",
    "\n",
    "    def print_tree(self):\n",
    "        self._print_node(self.root, spacing=\"\")\n",
    "\n",
    "    def _print_node(self, node, spacing):\n",
    "        if isinstance(node, LeafNode):\n",
    "            print(spacing + f\"Predict → {node.prediction}\")\n",
    "            return\n",
    "        print(spacing + f\"[X[{node.feature_index}] ≤ {node.threshold:.4f}]\")\n",
    "        print(spacing + \" ➜ True:\")\n",
    "        self._print_node(node.left, spacing + \"    \")\n",
    "        print(spacing + \" ➜ False:\")\n",
    "        self._print_node(node.right, spacing + \"    \")\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        num_samples, num_features = X.shape\n",
    "        # stopping criteria\n",
    "        if (depth == self.max_depth or\n",
    "            num_samples < self.min_samples_split or\n",
    "            len(set(y)) == 1):\n",
    "            leaf_label = Counter(y).most_common(1)[0][0]\n",
    "            return LeafNode(leaf_label)\n",
    "\n",
    "        parent_impurity = self._impurity(y)\n",
    "        best_gain = 0.0\n",
    "        best_feat = None\n",
    "        best_thresh = None\n",
    "\n",
    "        # find best split\n",
    "        for feat in range(num_features):\n",
    "            thresholds = np.unique(X[:, feat])\n",
    "            for thresh in thresholds:\n",
    "                left_mask = X[:, feat] <= thresh\n",
    "                right_mask = ~left_mask\n",
    "                if left_mask.sum() == 0 or right_mask.sum() == 0:\n",
    "                    continue\n",
    "                gain = self._information_gain(y, left_mask, right_mask, parent_impurity)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feat = feat\n",
    "                    best_thresh = thresh\n",
    "\n",
    "        # no valid split found\n",
    "        if best_gain < self.min_impurity_decrease:\n",
    "            leaf_label = Counter(y).most_common(1)[0][0]\n",
    "            return LeafNode(leaf_label)\n",
    "\n",
    "        # split on best feature/threshold\n",
    "        mask_left = X[:, best_feat] <= best_thresh\n",
    "        mask_right = ~mask_left\n",
    "        left_subtree = self._build_tree(X[mask_left], y[mask_left], depth+1)\n",
    "        right_subtree = self._build_tree(X[mask_right], y[mask_right], depth+1)\n",
    "        return DecisionNode(best_feat, best_thresh, left_subtree, right_subtree)\n",
    "\n",
    "    def _impurity(self, y):\n",
    "        counts = np.bincount(y, minlength=self.n_classes)\n",
    "        ps = counts / counts.sum()\n",
    "        if self.criterion == \"gini\":\n",
    "            return 1 - np.sum(ps**2)\n",
    "        elif self.criterion == \"entropy\":\n",
    "            return -np.sum([p * np.log2(p) for p in ps if p > 0])\n",
    "        else:  # misclassification error\n",
    "            return 1 - np.max(ps)\n",
    "\n",
    "    def _information_gain(self, y, left_mask, right_mask, parent_impurity):\n",
    "        n = len(y)\n",
    "        n_left = left_mask.sum()\n",
    "        n_right = right_mask.sum()\n",
    "        imp_left = self._impurity(y[left_mask])\n",
    "        imp_right = self._impurity(y[right_mask])\n",
    "        child_impurity = (n_left/n)*imp_left + (n_right/n)*imp_right\n",
    "        return parent_impurity - child_impurity\n",
    "\n",
    "    def _predict_one(self, x, node):\n",
    "        if isinstance(node, LeafNode):\n",
    "            return node.prediction\n",
    "        if x[node.feature_index] <= node.threshold:\n",
    "            return self._predict_one(x, node.left)\n",
    "        else:\n",
    "            return self._predict_one(x, node.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9035087719298246\n",
      "Sklearn Accuracy: 0.9122807017543859\n"
     ]
    }
   ],
   "source": [
    "tree = CustomDecisionTreeClassifier(max_depth=5, min_samples_split=2, criterion=\"gini\")\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy(y_test, y_pred))\n",
    "\n",
    "# Check if the implementation is correct\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "sk_tree = DecisionTreeClassifier(max_depth=5, min_samples_split=2, criterion=\"gini\")\n",
    "sk_tree.fit(X_train, y_train)\n",
    "y_sk_pred = sk_tree.predict(X_test)\n",
    "\n",
    "print(\"Sklearn Accuracy:\", accuracy(y_test, y_sk_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-mlcore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
